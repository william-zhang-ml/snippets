{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84789ae7",
   "metadata": {},
   "source": [
    "The code below is my extended implementation of sigmoid focal loss.\n",
    "\n",
    "`torchvision`'s (v0.11.3) `sigmoid_focal_loss` implementation takes a simple average/sum across pixels. This is not ideal with severe foreground/background imbalance. There IS an `alpha` parameter that modifies foreground and background pixel losses. But this approach requires very high `alpha` values to combat imbalance. The loss would be driven by a few foreground pixels where the number of foreground pixels varies (think going from 20 objects to 5 objects). This results in noisy loss values.\n",
    "\n",
    "Applying a class weight AFTER averaging pixel losses by class should provide more effective and stable loss values than applying a class weight BEFORE averaging.\n",
    "\n",
    "Other loss functions may also benefit from similar treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e5d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "\n",
    "def balanced_focal_loss(inputs: Tensor,\n",
    "                        targets: Tensor,\n",
    "                        alpha: float = 0.5,\n",
    "                        beta: float = 0.75,\n",
    "                        gamma: float = 2) -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute per-sample binary focal loss as\n",
    "    the weighted sum of the average foreground and average background loss.\n",
    "\n",
    "    This function wraps torchvision.ops.sigmoid_focal_loss.\n",
    "\n",
    "    Args:\n",
    "        inputs:  float tensor of arbitrary shape,\n",
    "                 the predictions for each example\n",
    "        targets: float tensor with the same shape as inputs,\n",
    "                 the binary classification label for each element in inputs,\n",
    "                 (0 for the negative class and 1 for the positive class)\n",
    "        alpha:   weighting factor in range (0,1) to balance\n",
    "                 positive vs negative pixels\n",
    "        beta:    weighting factor in range (0,1) to balance\n",
    "                 positive vs negative pixel averages\n",
    "        gamma:   exponent of the modulating factor (1 - p_t)\n",
    "                 to balance easy vs hard examples.\n",
    "    \"\"\"\n",
    "    pixel_loss = sigmoid_focal_loss(\n",
    "        inputs=inputs,\n",
    "        targets=targets,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        reduction='none')\n",
    "\n",
    "    # nansum after mean turns nan to 0 when indexing gives no elements back\n",
    "    fg_loss = torch.stack(\n",
    "        [loss[t == 1].mean().nansum() for loss, t in zip(pixel_loss, targets)])\n",
    "    bg_loss = torch.stack(\n",
    "        [loss[t == 0].mean().nansum() for loss, t in zip(pixel_loss, targets)])\n",
    "\n",
    "    return beta * fg_loss + (1 - beta) * bg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938574d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev-env",
   "language": "python",
   "name": "ml-dev-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
